+++
title = "The Adolescence of Technology: Dismantling Power Positions"
description = "What Dario Amodei's essay on AI risks teaches us about technology that challenges entrenched positions of powerâ€”and what it takes to navigate the transition."
tags = ["Technology", "Power", "Disruption", "Systems", "Change"]
published_at = "2026-01-29T21:00:00+00:00"
+++

There's a question that haunts anyone building technology that threatens established power. How do you dismantle a position of strength without simply replacing one monopoly with another?

[Dario Amodei's recent essay, "The Adolescence of Technology,"](https://www.darioamodei.com/essay/the-adolescence-of-technology) addresses AI risks from a radically different angle. His framework offers a blueprint for anyone attempting to redistribute power in an industry. The careful navigation between doomerism and techno-utopianism. The acknowledgment of uncertainty. The insistence on surgical intervention rather than sweeping mandates.

I've been thinking about this in the context of technology that has the potential to dismantle entrenched positions of power. Not because I believe these technologies are existentially dangerous, but because they share a fundamental characteristic with powerful AI: they redistribute capabilities that were previously concentrated.

## The GitHub Problem

Every developer exists within a web of dependencies that shape their choices. The social graph determines where your contributions live, where your reputation accumulates, where your network resides. The discovery graph controls how new projects and tools get found, recommended, and adopted. The integration graph represents the tools and services that connect to each other, creating compound lock-in. The attention graph decides who sees your work, who can benefit from it, who gets to decide what is visible.

In our industry, all of these graphs flow through a single company: GitHub.

This is not a conspiracy. It is the result of years of network effects, strategic acquisitions, and building what developers actually needed at the time. But it creates something that looks a lot like a power position. Your professional identity is hosted on their servers. Your project's visibility depends on their algorithms and editorial choices. Your integrations are dependencies on their ecosystem. Your workflow is optimized for their platform, not your needs.

GitHub did not set out to create a monopoly. They built something useful and won. But now we are in a world where a resume-ready open source contribution history requires a GitHub profile. CI/CD tools integrate most naturally with GitHub Actions. Package registries default to GitHub's. Recruitment processes expect GitHub profile URLs. The term "GitHub star" has become a de facto currency in open source.

This is what a dominant position looks like. It is not about one feature being better. It is about the accumulated weight of network effects, integrations, and behavioral expectations creating switching costs that have nothing to do with the underlying value proposition.

## The Adolescence Moment

Amodei argues that powerful AI will arrive in a technological adolescence. This is a transitional period where humanity has been handed almost unimaginable power but may not have the maturity to wield it. The same dynamic applies to technology that challenges entrenched positions like GitHub's dominance.

There is a moment, often unexpected, where a new approach becomes capable enough to threaten established players. The incumbent still has overwhelming advantages: resources, users, brand recognition, talent, and in GitHub's case, years of network effects that compound daily. But the challenger has something the incumbent cannot easily replicate. A different set of incentives. A different relationship with users. A different definition of success.

Consider GitHub's position. They have built the dominant platform through genuine value creation. But their incentives are now aligned with platform optimization, not developer empowerment. They acquired npm to integrate it into their ecosystem. They built GitHub Actions to increase lock-in. Every strategic move makes sense from their position. But it also deepens the moat.

This is the adolescence. It is turbulent. It is uncertain. And it is when the most important decisions get made.

## Lessons from Amodei's Framework

Amodei spends considerable time distinguishing legitimate risk analysis from doomerism. This is a quasi-religious belief that doom is inevitable. But he also rejects the opposite extreme: the belief that technology always works out for the best.

In the context of dismantling power positions, this means acknowledging genuine challenges. Replacing a monopoly is hard. The new technology will have bugs, gaps, and limitations. Pretending otherwise is self-deception. It also means rejecting inevitability narratives. Neither the incumbent crushing the challenger nor the challenger inevitably winning is true. Outcomes depend on choices. And it means staying empirical. Measure what actually works. Build feedback loops. Adjust based on evidence rather than ideology.

Amodei is explicit about uncertainty. Nothing in his analysis is certain. AI might not advance as fast as projected. Risks might not materialize. Unknown risks might emerge. The same intellectual honesty applies to decentralization. You do not know what you do not know. The incumbent's next move is unpredictable. Market dynamics are complex. Developer behavior is harder to model than you think. Plans will fail. Your strategy for dismantling a power position will need revision, multiple revisions. The future is not written. Neither the incumbent's dominance nor the challenger's success is fated. Both outcomes remain possible until the choices are made.

This is Amodei's most practical contribution: surgical interventions. Addressing AI risks requires approaches that are minimally destructive, so you do not burn down the industry to save it. Surgical, targeting specific problems rather than sweeping mandates. Reversible, so if an intervention does not work, you can walk it back.

For technology challenging power positions, this translates to building incrementally. Ship small changes that you can measure and reverse. Do not bet the company on a single grand vision. Create escape hatches. If your technology becomes successful, ensure users can leave. Actually leave. With their data. With their relationships. With their dignity intact. And coordinate with incumbents where possible. Some transitions can be collaborative. Others will be zero-sum. Know the difference.

## The Parallel Risks

Amodei identifies five categories of AI risk. Each has a parallel in power redistribution.

### Autonomy Risks and Governance Risks

AI might pursue goals that diverge from human intentions. In power redistribution, the challenger might develop its own incentives that diverge from its original mission. Success creates new pressures. New pressures create new priorities. Before you know it, you are optimizing for growth metrics instead of user value.

The parallel question is: how do you maintain the original mission when you have power to protect? Amodei's answer for AI is Constitutional AI, training with high-level principles rather than specific instructions. For challenger technology, the answer is similar. Build principles into the foundation, not just the code.

### Misuse for Destruction and Capture by Incumbents

AI could be misused by bad actors to cause harm. Similarly, technology built to challenge incumbents could be captured by them, acquired, neutralized, or cloned. Amodei's response is layered: transparency, monitoring, public disclosure. For challenger technology, the parallel is open governance. Make the technology's incentives visible. Let users see how decisions get made. Build in public.

### Seizing Power and Becoming the New Monopoly

This is the central fear. You set out to dismantle a monopoly and end up becoming one. The power position is preserved, just with a different name on the letterhead. Amodei's framework suggests two answers.

First, design for dispersal. Build technology that cannot be easily centralized. Decentralized protocols rather than centralized platforms. Interoperability rather than lock-in. Data portability rather than proprietary formats.

Second, accept that you might fail. The honest acknowledgment that you could become the thing you set out to destroy is precisely what makes it less likely. The incumbents never had this doubt. That is partly why they are vulnerable, and also partly why they persist.

### Economic Disruption and Transition Costs

AI might cause mass unemployment. Power redistribution might cause mass disruption. Jobs lost. Careers upended. Ecosystems transformed. Someone always pays the price of progress. Amodei does not have a perfect answer here. He advocates for surgical interventions and acknowledges that some disruption is inevitable but should be minimized. For technology challenging power positions, the parallel is care for the transition. Help people adapt. Build in migration paths. Do not celebrate the incumbent's pain. Remember that the humans affected have valid concerns.

### Indirect Effects and Unintended Consequences

Amodei's final category is the hardest to predict: second and third-order effects that ripple through society. The same applies to power redistribution. You solve one problem and create three others. The only defense is humility. Stay open to feedback. Watch for warning signs. Accept that you will not anticipate everything.

## The National Security Framing

Amodei offers a provocative thought experiment. Imagine a country of geniuses materialized in 2027, fifty million Nobel-level capabilities operating ten times faster than humans. A national security advisor would call this the single most serious threat we have faced in a century.

Apply the same framing to GitHub's dominance. Imagine a credible alternative emerges that genuinely challenges their position. What would Microsoft's strategic response look like? What would the challenger's response to that response look like? What second-order effects ripple through the ecosystem?

GitHub is not going anywhere tomorrow. But they are not immune to competitive pressure either. The question is whether that pressure comes from genuine alternatives or from regulatory intervention, and whether the industry can evolve without catastrophic disruption.

This is not defeatism. It is strategic clarity. Understanding the forces at play, including the possibility that you might become the thing you set out to oppose, is prerequisite to navigating the transition well.

## What Success Looks Like

Amodei ends with a claim of optimism. He believes deeply in humanity's spirit and its nobility, but we must face the situation squarely without illusions.

For technology that challenges power positions, success looks like a more distributed ecosystem, with power genuinely dispersed rather than transferred. User agency, so people can leave, choose, and adapt without losing everything. Continued evolution, so the technology itself remains open to improvement and critique. And the original mission intact. You did not become the thing you set out to dismantle.

None of this is guaranteed. But none of it is impossible either.

## The Unanswered Questions

Amodei admits uncertainty about AI's trajectory. The same uncertainty applies here. Can you decentralize without fragmenting? Is there a path between monopoly and chaos? Do developers actually want agency? Or do they prefer convenience and the illusion of safety? What happens when the transition completes? Is there a stable end state, or is constant disruption the new normal? Who pays for the transition? The incumbent? The challenger? Developers? Society?

These questions do not have answers yet. That is what makes this moment an adolescence. Neither childhood, the comfortable old order, nor adulthood, a stable new equilibrium. Just the uncomfortable, uncertain, necessary passage between the two.

## The Alien's Question

Amodei opens with a scene from Carl Sagan's Contact. The astronomer is asked what question she would pose to aliens. Her answer: "How did you do it? How did you evolve, how did you survive this technological adolescence without destroying yourself?"

We do not have the aliens' answer. We are writing it ourselves, one choice at a time.

The technology that dismantles power positions is neither savior nor destroyer. It is a force multiplier. For good intentions and bad. For user empowerment and vendor lock-in. For disruption and stability.

The outcome depends on us. Not on inevitability. Not on technology's inherent properties. On the choices we make, the principles we embed, and the willingness to face the situation squarely without illusions.

That is the adolescence. And we are living in it.
